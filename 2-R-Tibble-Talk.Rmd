---
title: "R Data Types"
author: "Angela Zoss"
date: "`r Sys.Date()`"
output: html_document
---

```{r}

# Run the first time you start working with this file

install.packages("tidyverse")
install.packages("readxl")


```


```{r}

# Loading required packages

library(tidyverse)
library(readxl)

```

## Tidyverse: Sequences of Operations

Almost every data science toolkit is going to have a way of chaining together 
different kinds of data operations to form a longer sequence. Basically, this saves
you from having to store the results of each operation in a separate variable.

For example:

```{r}

days_per_year <- 365
hours_per_year <- days_per_year * 24
minutes_per_year <- hours_per_year * 60

minutes_per_year

```

With mathematical operations, we can just write them in a long line.

```{r}

minutes_per_year <- 365 * 24 * 60

minutes_per_year

```

That's where we want to get with datasets, too. But we have to learn one tool first -
the syntax for chaining functions together in R (or, at least, in `tidyverse` packages).

## The magrittr pipe

`%>%`

That's the syntax. It's called a pipe, and it was originally developed for a package
called magrittr. (Many R packages end with a single r, rather than "er.")

The pipe works by taking whatever the result of the previous command is and injecting
or piping it straight into the next command. Let's start with a simple example.

Here is a basic function that returns the class of a data element in R: `class()`.
Inside the parentheses, you would normally type the variable name or the data element
you want to find the class of. If you want to use the pipe, though, you could start
with the data element and then pipe it to the `class()` function.

```{r}

class("a")

"a" %>% class()

```

Those two statements are identical. When you use the pipe, whatever was on the left
side of the pipe gets inserted into the parentheses of the function on the right.

We haven't learned many functions yet, but let me introduce another very useful one.
It is the `seq()` function, and it can be used to create a vector of values based on 
a sequence. For example, you could create a sequence of all of the even numbers up
to 100, or count by fives or 10s.

To find the help page for a function, you can use a question mark `?` followed by the
function name.

```{r}

?seq

```

Let's use a sequence from 0 to 100, counting by 10s.

```{r}

seq(from = 0, to = 100, by = 10)

```

Now, let's say I want to learn the class of that sequence. Let's try it the long
way.

```{r}

tens <- seq(from = 0, to = 100, by = 10)
class(tens)

```

Now, using the pipe.

```{r}

seq(from = 0, to = 100, by = 10) %>% class()

```

Is it bad to store things as variables? Not at all! But sometimes it's just not
necessary and can interrupt the flow of a set of data steps. Also, the more
variables you're storing, the harder it might be to keep track of them, and you might
accidentally end up using the wrong one at some point.

I usually store or print results temporary while I'm building a set of steps. When 
I'm confident the steps make sense and are working the way I want, I will try to
simplify them into a chain that makes sense. Of course, it's always good to be testing
the results of any data science process to make sure your results are what you expect.

## Loading data

Piping vectors is all well and good, but ultimately our goal is to use pipes to help
us work with tabular data more naturally. Let's load some data.

The `tidyverse` comes with some built-in data loading functions that I recommend
over the ones that are included in base R. The ones I use most commonly are `read_csv`
and `read_xlsx`, which is actually in a separate package called `readxl`. 

Both of these functions can load data either from a local data file or from something
shared on the web. Let's grab the dataset from the Open Refine lesson for Library Carpentries.

```{r}

lc_open_refine <- read_csv(
  'https://github.com/LibraryCarpentry/lc-open-refine/raw/gh-pages/data/doaj-article-sample.csv',
  col_types = cols(.default = "c", Date = col_date(format="%m/%d/%Y")) 
  )

```

The `read_csv()` function does a few things automatically. It assumes that the first 
row of the dataset contained the column names. It can also each column to try to guess 
the data type. Usually the tidyverse data reading functions do a great job of guessing
data types, but you can also specify them manually if you need to. Here, I specified
that Date is a date but all others are character variables.

We spent a long time talking about data types and accessing data. Now that we have
a dataset and are learning how to use the pipe, I want to show a few handy functions 
for accessing data in a data frame.

## `select()` for isolating columns

Instead of using `$` or `[]` or `[[]]` to grab one of the columns in the data frame,
let's use our words.

The `select()` function has a wide variety of ways to specify the columns you want.
Let's start with names. To select by name, all you have to do is list all of the
column names you want, separated by commas. The first argument in the function
will always be the name of the data frame.

```{r}

select(lc_open_refine, Title, Authors)

```

I don't know about you, but I prefer that to having to remember the punctuation marks.

What else can you do with `select()`? You can still use `-` to exclude columns, but now
you can do it by name.

```{r}

select(lc_open_refine, -Subjects)

```


```{r}

select(lc_open_refine, -Language, -Citation)

```

What if you have a group of columns that all have similar names and you want to
include or exclude all of them? You can use a helper function called `starts_with()`.

```{r}

select(lc_open_refine, starts_with('L'))

select(lc_open_refine, -starts_with('L'))

```

### `select()` Helper Functions

#### String search functions

* starts_with(): look for a substring at the beginning of the column name
* contains(): look for a substring anywhere in the column name
* ends_with(): look for a substring at the end of the column name
* matches(): look for a regular expression pattern in the column name
* num_range(): look for a set of columns that contains the specified number range

#### Set functions

* all_of(): throws error if any columns in list are missing; good if you have a pre-defined
list of column names you're expecting
* any_of(): returns any in list that are there, ignores missing ones

#### Position functions
* everything(): select everything; can be used to reorder variables
* last_col(): selects just the last column, but can also use an offset to count in from the end

#### Make your own test

* where(): use any function that returns true or false for each column vector (the values, not the name)

```{r}

select(lc_open_refine, DOI, everything())
select(lc_open_refine, where(is.numeric))

```

You can mix and match these kinds of options, too.

```{r}

select(lc_open_refine, starts_with('L'), DOI)

select(lc_open_refine, starts_with('L'), DOI, everything(), -URL)

```

You can even use some punctuation, but more flexibly than in base R. For example, 
the colon `:` still specifies a range, but you can say a range of names, and you
don't need a `c()`.

```{r}

select(lc_open_refine, Title:Subjects)

```

See the `select()` help documentation for more tips and examples.

Now, let's talk about rows.

## `filter()` for isolating rows

In `tidyverse`, the function for retrieving a set of rows is `filter()`. Usually, 
if you're limiting a dataset to a subset of rows, you want to do it on some specific
criteria, usually related to the data.

Remember the syntax we used for vector subsets?

`sample_vector[sample_vector > 4]`

We're back to something like that. This time, we're going to specify the name of
the data frame, and then we're going to refer to the column and build the test, all
inside the `filter()` function. This is a bit trickier because all of our variables
are text variables and we haven't learned much that we can do with them yet. Luckily,
our Date column can be treated like a number. We can also test for simple equivalence,
like rows where the language is (or is not) "EN".

```{r}

filter(lc_open_refine, Date < as.Date("2015-01-02"))

filter(lc_open_refine, Language != "EN")

```

## Remove empty DOIs


## Fix inconsistencies in Publisher

## Fix inconsistencies in Language

## Split apart and clean Subjects, then re-join

## Make API calls with DOI

## Parse API result



## General things to cover

* mutate
* pivot
* export
* joining tables
* grouping?
* glimpse?
* glue?
* string functions in general, regex?
* dbplyr?